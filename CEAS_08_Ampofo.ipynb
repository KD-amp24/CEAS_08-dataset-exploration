{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a5c267b-e562-47ae-abba-2a45ab1c9d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:471: SyntaxWarning: invalid escape sequence '\\Y'\n",
      "<>:471: SyntaxWarning: invalid escape sequence '\\Y'\n",
      "C:\\Users\\Amponsah\\AppData\\Local\\Temp\\ipykernel_12240\\2177349502.py:471: SyntaxWarning: invalid escape sequence '\\Y'\n",
      "  DATA_PATH = \"D:\\Year 2 semester 2\\Sys. and Proj\\Data Analysis on Phishing Emails\\CEAS_08.csv\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Dataset loaded ===\n",
      "shape: (39154, 19)\n",
      "\n",
      "=== Head (3 rows) ===\n",
      "                                              sender  \\\n",
      "0                   Young Esposito <Young@iworld.de>   \n",
      "1                       Mok <ipline's1983@icable.ph>   \n",
      "2  Daily Top 10 <Karmandeep-opengevl@universalnet...   \n",
      "\n",
      "                        receiver                             date  \\\n",
      "0    user4@gvc.ceas-challenge.cc  Tue, 05 Aug 2008 16:31:02 -0700   \n",
      "1  user2.2@gvc.ceas-challenge.cc  Tue, 05 Aug 2008 18:31:03 -0500   \n",
      "2  user2.9@gvc.ceas-challenge.cc  Tue, 05 Aug 2008 20:28:00 -1200   \n",
      "\n",
      "                     subject  \\\n",
      "0  Never agree to be a loser   \n",
      "1     Befriend Jenna Jameson   \n",
      "2       CNN.com Daily Top 10   \n",
      "\n",
      "                                                body  label  urls  \\\n",
      "0  Buck up, your troubles caused by small dimensi...      1     1   \n",
      "1  \\nUpgrade your sex and pleasures with these te...      1     1   \n",
      "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...      1     1   \n",
      "\n",
      "                date_parsed  \\\n",
      "0 2008-08-05 23:31:02+00:00   \n",
      "1 2008-08-05 23:31:03+00:00   \n",
      "2 2008-08-06 08:28:00+00:00   \n",
      "\n",
      "                                            text_raw  \\\n",
      "0  Never agree to be a loser Buck up, your troubl...   \n",
      "1  Befriend Jenna Jameson \\nUpgrade your sex and ...   \n",
      "2  CNN.com Daily Top 10 >+=+=+=+=+=+=+=+=+=+=+=+=...   \n",
      "\n",
      "                                          text_clean  subject_len  body_len  \\\n",
      "0  never agree to be a loser buck up your trouble...           25       273   \n",
      "1  befriend jenna jameson upgrade your sex and pl...           22        82   \n",
      "2  cnn com daily top 10 the daily top 10 from cnn...           20      3918   \n",
      "\n",
      "   text_len  has_url_in_text  hour_utc weekday_utc  \\\n",
      "0       299                1      23.0     Tuesday   \n",
      "1       102                1      23.0     Tuesday   \n",
      "2      3939                1       8.0   Wednesday   \n",
      "\n",
      "                              sender_email        sender_domain  \\\n",
      "0                          young@iworld.de            iworld.de   \n",
      "1                   ipline's1983@icable.ph            icable.ph   \n",
      "2  karmandeep-opengevl@universalnet.psi.br  universalnet.psi.br   \n",
      "\n",
      "         receiver_domain  \n",
      "0  gvc.ceas-challenge.cc  \n",
      "1  gvc.ceas-challenge.cc  \n",
      "2  gvc.ceas-challenge.cc  \n",
      "\n",
      "=== Info ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 39154 entries, 0 to 39153\n",
      "Data columns (total 19 columns):\n",
      " #   Column           Non-Null Count  Dtype              \n",
      "---  ------           --------------  -----              \n",
      " 0   sender           39154 non-null  object             \n",
      " 1   receiver         39154 non-null  object             \n",
      " 2   date             39154 non-null  object             \n",
      " 3   subject          39154 non-null  object             \n",
      " 4   body             39154 non-null  object             \n",
      " 5   label            39154 non-null  Int64              \n",
      " 6   urls             39154 non-null  int64              \n",
      " 7   date_parsed      39139 non-null  datetime64[ns, UTC]\n",
      " 8   text_raw         39154 non-null  object             \n",
      " 9   text_clean       39154 non-null  object             \n",
      " 10  subject_len      39154 non-null  int64              \n",
      " 11  body_len         39154 non-null  int64              \n",
      " 12  text_len         39154 non-null  int64              \n",
      " 13  has_url_in_text  39154 non-null  int64              \n",
      " 14  hour_utc         39139 non-null  float64            \n",
      " 15  weekday_utc      39139 non-null  object             \n",
      " 16  sender_email     39154 non-null  object             \n",
      " 17  sender_domain    39154 non-null  object             \n",
      " 18  receiver_domain  39154 non-null  object             \n",
      "dtypes: Int64(1), datetime64[ns, UTC](1), float64(1), int64(5), object(11)\n",
      "memory usage: 5.7+ MB\n",
      "None\n",
      "\n",
      "=== Missing values (top 15) ===\n",
      "weekday_utc    15\n",
      "hour_utc       15\n",
      "date_parsed    15\n",
      "date            0\n",
      "receiver        0\n",
      "sender          0\n",
      "subject         0\n",
      "urls            0\n",
      "text_raw        0\n",
      "label           0\n",
      "body            0\n",
      "subject_len     0\n",
      "text_clean      0\n",
      "text_len        0\n",
      "body_len        0\n",
      "dtype: int64\n",
      "\n",
      "=== Label counts ===\n",
      "label\n",
      "1    21842\n",
      "0    17312\n",
      "Name: count, dtype: Int64\n",
      "[saved] figures_ceas08\\01_label_distribution.png\n",
      "[saved] figures_ceas08\\02_urls_vs_label.png\n",
      "[saved] figures_ceas08\\03_text_length_hist.png\n",
      "[saved] figures_ceas08\\04_text_length_box_log.png\n",
      "[saved] figures_ceas08\\05_weekday_vs_label.png\n",
      "[saved] figures_ceas08\\06_hour_vs_label.png\n",
      "[saved] figures_ceas08\\07_subject_length_kde.png\n",
      "[saved] figures_ceas08\\08_subject_vs_body_scatter.png\n",
      "[saved] figures_ceas08\\09_sender_domain_topN_by_label.png\n",
      "[saved] figures_ceas08\\10_receiver_domain_topN_by_label.png\n",
      "[saved] figures_ceas08\\11_url_rate_by_sender_domain.png\n",
      "[saved] figures_ceas08\\12_wordcloud_legit.png\n",
      "[saved] figures_ceas08\\13_wordcloud_phishing.png\n",
      "\n",
      "Top terms (legit):\n",
      "submission    52424\n",
      "2008          20196\n",
      "added         19673\n",
      "sender        19465\n",
      "notes         18397\n",
      "virus         17239\n",
      "total         14795\n",
      "python        14203\n",
      "list          13839\n",
      "message       13589\n",
      "wrote         13486\n",
      "new           13118\n",
      "use           11043\n",
      "mail           9890\n",
      "university     9206\n",
      "like           9199\n",
      "feb            9035\n",
      "just           8606\n",
      "file           8471\n",
      "time           8401\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top terms (phishing/spam):\n",
      "cnn         25653\n",
      "com         16333\n",
      "news        12864\n",
      "2008        10543\n",
      "daily        8837\n",
      "network      8718\n",
      "settings     8677\n",
      "cable        8673\n",
      "replica      7747\n",
      "alert        7040\n",
      "time         6438\n",
      "email        6208\n",
      "going        5992\n",
      "videos       5930\n",
      "stories      5864\n",
      "lllp         5860\n",
      "watches      5685\n",
      "custom       5657\n",
      "aug          5521\n",
      "suspect      4836\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[saved] CEAS_08_cleaned.csv\n",
      "[done] Figures saved in: C:\\Users\\Amponsah\\figures_ceas08\n"
     ]
    }
   ],
   "source": [
    "#Naser Abdullah Alam. (2024). Phishing Email Dataset [Data set]. Kaggle. https://doi.org/10.34740/KAGGLE/DS/5074342\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Config\n",
    "# =============================================================================\n",
    "RANDOM_STATE = 42\n",
    "FIG_DIR = Path(\"figures_ceas08\")\n",
    "FIG_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Loading\n",
    "# =============================================================================\n",
    "def smart_read_email_dataset(path: str | Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Robust reader for Kaggle CEAS_08.csv.\n",
    "\n",
    "    Why special handling?\n",
    "    - 'body' often contains embedded newlines inside quoted strings\n",
    "    - some rows may be slightly malformed\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "\n",
    "    # 1) Fast attempt (C engine). Often works.\n",
    "    try:\n",
    "        df = pd.read_csv(\n",
    "            path,\n",
    "            sep=\",\",\n",
    "            quotechar='\"',\n",
    "            engine=\"c\",\n",
    "            low_memory=False,\n",
    "        )\n",
    "    except Exception:\n",
    "        # 2) More tolerant fallback (python engine)\n",
    "        df = pd.read_csv(\n",
    "            path,\n",
    "            sep=\",\",\n",
    "            quotechar='\"',\n",
    "            engine=\"python\",\n",
    "            on_bad_lines=\"skip\",\n",
    "        )\n",
    "\n",
    "    # Normalize col names\n",
    "    df.columns = [c.strip().lower() for c in df.columns]\n",
    "\n",
    "    expected = {\"sender\", \"receiver\", \"date\", \"subject\", \"body\", \"label\", \"urls\"}\n",
    "    missing = expected - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(\n",
    "            f\"Missing expected columns: {missing}\\n\"\n",
    "            f\"Found columns: {list(df.columns)}\\n\"\n",
    "            \"If Kaggle version differs, update expected column names accordingly.\"\n",
    "        )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Feature Engineering / Cleaning\n",
    "# =============================================================================\n",
    "def safe_to_datetime(series: pd.Series) -> pd.Series:\n",
    "    # Example: \"Tue, 05 Aug 2008 16:31:02 -0700\"\n",
    "    return pd.to_datetime(series, errors=\"coerce\", utc=True)\n",
    "\n",
    "\n",
    "def normalize_text(s: str) -> str:\n",
    "    \"\"\"\n",
    "    Simple text normalization for visualization/word clouds.\n",
    "    - lowercase\n",
    "    - strip URLs + emails\n",
    "    - remove punctuation\n",
    "    - collapse whitespace\n",
    "    \"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "\n",
    "    s = s.lower()\n",
    "\n",
    "    # URLs\n",
    "    s = re.sub(r\"http[s]?://\\S+|www\\.\\S+\", \" \", s)\n",
    "\n",
    "    # email addresses\n",
    "    s = re.sub(r\"\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b\", \" \", s)\n",
    "\n",
    "    # keep alnum + spaces\n",
    "    s = re.sub(r\"[^a-z0-9\\s]+\", \" \", s)\n",
    "\n",
    "    # collapse whitespace\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "\n",
    "def extract_email_from_sender(sender: str) -> str:\n",
    "    \"\"\"\n",
    "    sender examples:\n",
    "    - \"Young Esposito <Young@iworld.de>\"\n",
    "    - \"Mok <ipline's1983@icable.ph>\"\n",
    "    - \"Daily Top 10 <Karmandeep-opengevl@universalnet.psi.br>\"\n",
    "    - sometimes just an email, sometimes just a name\n",
    "    \"\"\"\n",
    "    if not isinstance(sender, str):\n",
    "        return \"\"\n",
    "\n",
    "    # Common pattern: <email@domain>\n",
    "    m = re.search(r\"<\\s*([^<>@\\s]+@[^<>@\\s]+)\\s*>\", sender)\n",
    "    if m:\n",
    "        return m.group(1).strip().lower()\n",
    "\n",
    "    # Otherwise, any email-like token in the string\n",
    "    m2 = re.search(r\"\\b([\\w\\.-]+@[\\w\\.-]+\\.\\w+)\\b\", sender)\n",
    "    if m2:\n",
    "        return m2.group(1).strip().lower()\n",
    "\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def extract_domain(email: str) -> str:\n",
    "    if not isinstance(email, str) or \"@\" not in email:\n",
    "        return \"\"\n",
    "    return email.split(\"@\", 1)[1].lower()\n",
    "\n",
    "\n",
    "def build_text_fields(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "\n",
    "    # Dates\n",
    "    df[\"date_parsed\"] = safe_to_datetime(df[\"date\"])\n",
    "\n",
    "    # Fill NA for text fields\n",
    "    df[\"subject\"] = df[\"subject\"].fillna(\"\")\n",
    "    df[\"body\"] = df[\"body\"].fillna(\"\")\n",
    "\n",
    "    # Raw and clean text\n",
    "    df[\"text_raw\"] = (df[\"subject\"].astype(str) + \" \" + df[\"body\"].astype(str)).str.strip()\n",
    "    df[\"text_clean\"] = df[\"text_raw\"].map(normalize_text)\n",
    "\n",
    "    # Simple lengths\n",
    "    df[\"subject_len\"] = df[\"subject\"].astype(str).str.len()\n",
    "    df[\"body_len\"] = df[\"body\"].astype(str).str.len()\n",
    "    df[\"text_len\"] = df[\"text_raw\"].astype(str).str.len()\n",
    "\n",
    "    # URLs\n",
    "    df[\"urls\"] = pd.to_numeric(df[\"urls\"], errors=\"coerce\")\n",
    "    df[\"has_url_in_text\"] = df[\"text_raw\"].str.contains(\n",
    "        r\"http[s]?://|www\\.\", regex=True, na=False\n",
    "    ).astype(int)\n",
    "\n",
    "    # Time features\n",
    "    df[\"hour_utc\"] = df[\"date_parsed\"].dt.hour\n",
    "    df[\"weekday_utc\"] = df[\"date_parsed\"].dt.day_name()\n",
    "\n",
    "    # Label\n",
    "    df[\"label\"] = pd.to_numeric(df[\"label\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # Sender email + domain\n",
    "    df[\"sender_email\"] = df[\"sender\"].map(extract_email_from_sender)\n",
    "    df[\"sender_domain\"] = df[\"sender_email\"].map(extract_domain)\n",
    "\n",
    "    # Receiver domain (sometimes helpful)\n",
    "    df[\"receiver\"] = df[\"receiver\"].fillna(\"\")\n",
    "    df[\"receiver_domain\"] = df[\"receiver\"].astype(str).str.extract(r\"@(.+)$\")[0].fillna(\"\").str.lower()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Plot helpers\n",
    "# =============================================================================\n",
    "def savefig(name: str) -> None:\n",
    "    out = FIG_DIR / name\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out, dpi=200)\n",
    "    print(f\"[saved] {out}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# EDA Plots (baseline)\n",
    "# =============================================================================\n",
    "def plot_label_distribution(df: pd.DataFrame) -> None:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    ax = sns.countplot(data=df, x=\"label\")\n",
    "    ax.set_title(\"Email Class Distribution (label)\")\n",
    "    ax.set_xlabel(\"Label (0=legit, 1=phishing/spam)\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    savefig(\"01_label_distribution.png\")\n",
    "\n",
    "\n",
    "def plot_urls_vs_label(df: pd.DataFrame) -> None:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(11, 4))\n",
    "\n",
    "    sns.countplot(data=df, x=\"urls\", hue=\"label\", ax=axes[0])\n",
    "    axes[0].set_title(\"Provided 'urls' Column vs Label\")\n",
    "    axes[0].set_xlabel(\"urls (as provided)\")\n",
    "    axes[0].set_ylabel(\"count\")\n",
    "\n",
    "    sns.countplot(data=df, x=\"has_url_in_text\", hue=\"label\", ax=axes[1])\n",
    "    axes[1].set_title(\"Detected URL in Subject/Body vs Label\")\n",
    "    axes[1].set_xlabel(\"has_url_in_text\")\n",
    "    axes[1].set_ylabel(\"count\")\n",
    "\n",
    "    savefig(\"02_urls_vs_label.png\")\n",
    "\n",
    "\n",
    "def plot_text_length_distributions(df: pd.DataFrame) -> None:\n",
    "    # clip long tail for nicer histogram view\n",
    "    text_len = df[\"text_len\"].dropna()\n",
    "    clip_max = np.percentile(text_len, 99) if len(text_len) else 0\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(\n",
    "        data=df,\n",
    "        x=np.clip(df[\"text_len\"], 0, clip_max),\n",
    "        hue=\"label\",\n",
    "        bins=50,\n",
    "        kde=True,\n",
    "    )\n",
    "    plt.title(\"Text Length Distribution (Subject+Body) by Label (clipped at 99th pct)\")\n",
    "    plt.xlabel(\"Text length (characters)\")\n",
    "    plt.ylabel(\"count\")\n",
    "    savefig(\"03_text_length_hist.png\")\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.boxplot(data=df, x=\"label\", y=\"text_len\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(\"Text Length by Label (log scale)\")\n",
    "    plt.xlabel(\"Label\")\n",
    "    plt.ylabel(\"Text length (characters, log)\")\n",
    "    savefig(\"04_text_length_box_log.png\")\n",
    "\n",
    "\n",
    "def plot_time_patterns(df: pd.DataFrame) -> None:\n",
    "    if df[\"date_parsed\"].notna().sum() < 10:\n",
    "        print(\"[skip] Not enough parsable dates for time plots.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.countplot(\n",
    "        data=df.dropna(subset=[\"weekday_utc\"]),\n",
    "        x=\"weekday_utc\",\n",
    "        hue=\"label\",\n",
    "        order=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"],\n",
    "    )\n",
    "    plt.title(\"Emails by Weekday (UTC) and Label\")\n",
    "    plt.xlabel(\"Weekday (UTC)\")\n",
    "    plt.ylabel(\"count\")\n",
    "    plt.xticks(rotation=25)\n",
    "    savefig(\"05_weekday_vs_label.png\")\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.histplot(\n",
    "        data=df.dropna(subset=[\"hour_utc\"]),\n",
    "        x=\"hour_utc\",\n",
    "        hue=\"label\",\n",
    "        bins=24,\n",
    "        multiple=\"stack\",\n",
    "    )\n",
    "    plt.title(\"Emails by Hour of Day (UTC) and Label\")\n",
    "    plt.xlabel(\"Hour (UTC)\")\n",
    "    plt.ylabel(\"count\")\n",
    "    savefig(\"06_hour_vs_label.png\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Additional Plots\n",
    "# =============================================================================\n",
    "def plot_subject_len_kde(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    KDE of subject length by label.\n",
    "    Some datasets have lots of very short subjects; clipping helps readability.\n",
    "    \"\"\"\n",
    "    subj = df[\"subject_len\"].dropna()\n",
    "    if subj.empty:\n",
    "        print(\"[skip] No subject length data.\")\n",
    "        return\n",
    "\n",
    "    clip_max = np.percentile(subj, 99)\n",
    "    tmp = df.copy()\n",
    "    tmp[\"subject_len_clip\"] = np.clip(tmp[\"subject_len\"], 0, clip_max)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.kdeplot(\n",
    "        data=tmp.dropna(subset=[\"subject_len_clip\", \"label\"]),\n",
    "        x=\"subject_len_clip\",\n",
    "        hue=\"label\",\n",
    "        common_norm=False,\n",
    "        fill=True,\n",
    "    )\n",
    "    plt.title(\"Subject Length KDE by Label (clipped at 99th pct)\")\n",
    "    plt.xlabel(\"Subject length (characters)\")\n",
    "    plt.ylabel(\"density\")\n",
    "    savefig(\"07_subject_length_kde.png\")\n",
    "\n",
    "\n",
    "def plot_subject_vs_body_scatter(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Relationship between subject and body length (scatter).\n",
    "    We sample for speed if dataset is huge.\n",
    "    \"\"\"\n",
    "    tmp = df.dropna(subset=[\"subject_len\", \"body_len\", \"label\"]).copy()\n",
    "\n",
    "    if len(tmp) == 0:\n",
    "        print(\"[skip] No data for subject/body scatter.\")\n",
    "        return\n",
    "\n",
    "    # Sample for speed / plot clarity\n",
    "    if len(tmp) > 5000:\n",
    "        tmp = tmp.sample(5000, random_state=RANDOM_STATE)\n",
    "\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    sns.scatterplot(data=tmp, x=\"subject_len\", y=\"body_len\", hue=\"label\", alpha=0.4)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(\"Subject Length vs Body Length (body log-scale)\")\n",
    "    plt.xlabel(\"Subject length (characters)\")\n",
    "    plt.ylabel(\"Body length (characters, log)\")\n",
    "    savefig(\"08_subject_vs_body_scatter.png\")\n",
    "\n",
    "\n",
    "def plot_sender_domain_frequency(df: pd.DataFrame, top_n: int = 20) -> None:\n",
    "    \"\"\"\n",
    "    Top sender domains overall + by label.\n",
    "    \"\"\"\n",
    "    tmp = df.copy()\n",
    "    tmp = tmp[tmp[\"sender_domain\"].astype(str).str.len() > 0]\n",
    "\n",
    "    if tmp.empty:\n",
    "        print(\"[skip] No sender domains extracted (sender_email may be missing).\")\n",
    "        return\n",
    "\n",
    "    # Top domains overall\n",
    "    top_domains = tmp[\"sender_domain\"].value_counts().head(top_n).index.tolist()\n",
    "    tmp_top = tmp[tmp[\"sender_domain\"].isin(top_domains)]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(\n",
    "        data=tmp_top,\n",
    "        y=\"sender_domain\",\n",
    "        order=tmp_top[\"sender_domain\"].value_counts().index,\n",
    "        hue=\"label\",\n",
    "    )\n",
    "    plt.title(f\"Top {top_n} Sender Domains (by Label)\")\n",
    "    plt.xlabel(\"count\")\n",
    "    plt.ylabel(\"sender_domain\")\n",
    "    savefig(\"09_sender_domain_topN_by_label.png\")\n",
    "\n",
    "\n",
    "def plot_receiver_domain_frequency(df: pd.DataFrame, top_n: int = 15) -> None:\n",
    "    \"\"\"\n",
    "    Useful sanity plot: top receiver domains (often includes dataset domains).\n",
    "    \"\"\"\n",
    "    tmp = df.copy()\n",
    "    tmp = tmp[tmp[\"receiver_domain\"].astype(str).str.len() > 0]\n",
    "\n",
    "    if tmp.empty:\n",
    "        print(\"[skip] No receiver domains extracted.\")\n",
    "        return\n",
    "\n",
    "    top_domains = tmp[\"receiver_domain\"].value_counts().head(top_n).index.tolist()\n",
    "    tmp_top = tmp[tmp[\"receiver_domain\"].isin(top_domains)]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(\n",
    "        data=tmp_top,\n",
    "        y=\"receiver_domain\",\n",
    "        order=tmp_top[\"receiver_domain\"].value_counts().index,\n",
    "        hue=\"label\",\n",
    "    )\n",
    "    plt.title(f\"Top {top_n} Receiver Domains (by Label)\")\n",
    "    plt.xlabel(\"count\")\n",
    "    plt.ylabel(\"receiver_domain\")\n",
    "    savefig(\"10_receiver_domain_topN_by_label.png\")\n",
    "\n",
    "\n",
    "def plot_url_rate_by_sender_domain(df: pd.DataFrame, top_n: int = 20) -> None:\n",
    "    \"\"\"\n",
    "    For top sender domains, show fraction of emails that contain URLs (detected in text).\n",
    "    \"\"\"\n",
    "    tmp = df.copy()\n",
    "    tmp = tmp[tmp[\"sender_domain\"].astype(str).str.len() > 0]\n",
    "    if tmp.empty:\n",
    "        print(\"[skip] No sender domains for URL rate plot.\")\n",
    "        return\n",
    "\n",
    "    top_domains = tmp[\"sender_domain\"].value_counts().head(top_n).index.tolist()\n",
    "    tmp = tmp[tmp[\"sender_domain\"].isin(top_domains)]\n",
    "\n",
    "    grp = tmp.groupby(\"sender_domain\", as_index=False)[\"has_url_in_text\"].mean()\n",
    "    grp = grp.sort_values(\"has_url_in_text\", ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=grp, y=\"sender_domain\", x=\"has_url_in_text\")\n",
    "    plt.title(f\"URL Presence Rate by Sender Domain (Top {top_n})\")\n",
    "    plt.xlabel(\"Mean(has_url_in_text)\")\n",
    "    plt.ylabel(\"sender_domain\")\n",
    "    savefig(\"11_url_rate_by_sender_domain.png\")\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Wordclouds + Token Counts\n",
    "# =============================================================================\n",
    "def make_wordcloud(text: str, title: str, outfile: str) -> None:\n",
    "    if not text.strip():\n",
    "        print(f\"[skip] Empty text for wordcloud: {title}\")\n",
    "        return\n",
    "\n",
    "    wc = WordCloud(\n",
    "        width=1200,\n",
    "        height=600,\n",
    "        background_color=\"white\",\n",
    "        stopwords=set(ENGLISH_STOP_WORDS),\n",
    "        max_words=200,\n",
    "    ).generate(text)\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    savefig(outfile)\n",
    "\n",
    "\n",
    "def wordclouds_by_label(df: pd.DataFrame) -> None:\n",
    "    legit = \" \".join(df.loc[df[\"label\"] == 0, \"text_clean\"].dropna().astype(str).tolist())\n",
    "    phish = \" \".join(df.loc[df[\"label\"] == 1, \"text_clean\"].dropna().astype(str).tolist())\n",
    "\n",
    "    make_wordcloud(legit, \"WordCloud: Legitimate Emails (label=0)\", \"12_wordcloud_legit.png\")\n",
    "    make_wordcloud(phish, \"WordCloud: Phishing/Spam Emails (label=1)\", \"13_wordcloud_phishing.png\")\n",
    "\n",
    "\n",
    "def top_terms_quick(df: pd.DataFrame, n: int = 20) -> None:\n",
    "    \"\"\"\n",
    "    Quick token frequency comparison per label (no heavy NLP).\n",
    "    \"\"\"\n",
    "    def token_counts(texts: pd.Series) -> pd.Series:\n",
    "        words = \" \".join(texts.dropna().astype(str)).split()\n",
    "        words = [w for w in words if w not in ENGLISH_STOP_WORDS and len(w) > 2]\n",
    "        return pd.Series(words).value_counts()\n",
    "\n",
    "    legit_counts = token_counts(df.loc[df[\"label\"] == 0, \"text_clean\"])\n",
    "    phish_counts = token_counts(df.loc[df[\"label\"] == 1, \"text_clean\"])\n",
    "\n",
    "    print(\"\\nTop terms (legit):\")\n",
    "    print(legit_counts.head(n))\n",
    "\n",
    "    print(\"\\nTop terms (phishing/spam):\")\n",
    "    print(phish_counts.head(n))\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# Main\n",
    "# =============================================================================\n",
    "def main() -> None:\n",
    "    # Put CEAS_08.csv in the same folder as this script OR provide full path here.\n",
    "    DATA_PATH = \"D:\\Year 2 semester 2\\Sys. and Proj\\Data Analysis on Phishing Emails\\CEAS_08.csv\"\n",
    "\n",
    "    df = smart_read_email_dataset(DATA_PATH)\n",
    "    df = build_text_fields(df)\n",
    "\n",
    "    # -------------------------\n",
    "    # Basic exploration\n",
    "    # -------------------------\n",
    "    print(\"\\n=== Dataset loaded ===\")\n",
    "    print(\"shape:\", df.shape)\n",
    "\n",
    "    print(\"\\n=== Head (3 rows) ===\")\n",
    "    print(df.head(3))\n",
    "\n",
    "    print(\"\\n=== Info ===\")\n",
    "    print(df.info())\n",
    "\n",
    "    print(\"\\n=== Missing values (top 15) ===\")\n",
    "    print(df.isna().sum().sort_values(ascending=False).head(15))\n",
    "\n",
    "    print(\"\\n=== Label counts ===\")\n",
    "    print(df[\"label\"].value_counts(dropna=False))\n",
    "\n",
    "    # -------------------------\n",
    "    # Plots (baseline)\n",
    "    # -------------------------\n",
    "    plot_label_distribution(df)\n",
    "    plot_urls_vs_label(df)\n",
    "    plot_text_length_distributions(df)\n",
    "    plot_time_patterns(df)\n",
    "\n",
    "    # -------------------------\n",
    "    # Additional plots\n",
    "    # -------------------------\n",
    "    plot_subject_len_kde(df)\n",
    "    plot_subject_vs_body_scatter(df)\n",
    "    plot_sender_domain_frequency(df, top_n=20)\n",
    "    plot_receiver_domain_frequency(df, top_n=15)\n",
    "    plot_url_rate_by_sender_domain(df, top_n=20)\n",
    "\n",
    "    # -------------------------\n",
    "    # Wordclouds + quick terms\n",
    "    # -------------------------\n",
    "    wordclouds_by_label(df)\n",
    "    top_terms_quick(df, n=20)\n",
    "\n",
    "    # -------------------------\n",
    "    # Save a cleaned export\n",
    "    # -------------------------\n",
    "    out_csv = \"CEAS_08_cleaned.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"\\n[saved] {out_csv}\")\n",
    "    print(f\"[done] Figures saved in: {FIG_DIR.resolve()}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d4311-9e56-4f18-89cf-ed1291e02231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beba8188-d6b3-402f-ae3d-b07bcbaae106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
